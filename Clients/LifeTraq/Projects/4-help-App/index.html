<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>4-help App - Voice Assistant</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        :root {
            --primary-black: #1a1a1a;
            --primary-white: #f8f8f8;
            --sage-green: #7a9d7e;
            --accent-green: #5a7d5e;
            --border-width: 3px;
            --shadow-offset: 4px;
            --transition: 0.3s ease;
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background: linear-gradient(135deg, var(--primary-white) 0%, #e8e8e8 100%);
            color: var(--primary-black);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }

        .container {
            width: 100%;
            max-width: 600px;
            background: var(--primary-white);
            border: var(--border-width) solid var(--primary-black);
            box-shadow: var(--shadow-offset) var(--shadow-offset) 0 var(--primary-black);
            padding: 2rem;
        }

        header {
            text-align: center;
            margin-bottom: 2rem;
            padding-bottom: 1.5rem;
            border-bottom: var(--border-width) solid var(--primary-black);
        }

        h1 {
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
            color: var(--primary-black);
        }

        .subtitle {
            font-size: 1rem;
            color: #666;
            font-weight: 500;
        }

        .voice-interface {
            margin-bottom: 2rem;
        }

        .status-indicator {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 0.75rem;
            margin-bottom: 2rem;
            padding: 1rem;
            background: linear-gradient(135deg, #f0f0f0 0%, #e0e0e0 100%);
            border: var(--border-width) solid var(--primary-black);
        }

        .status-dot {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background: #999;
            transition: var(--transition);
        }

        .status-indicator.ready .status-dot {
            background: var(--sage-green);
        }

        .status-indicator.connecting .status-dot {
            background: #f39c12;
            animation: pulse 1.5s infinite;
        }

        .status-indicator.active .status-dot {
            background: #27ae60;
            animation: pulse 1s infinite;
        }

        .status-indicator.error .status-dot {
            background: #e74c3c;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }

        .status-text {
            font-size: 0.9rem;
            font-weight: 600;
            color: var(--primary-black);
        }

        .voice-control {
            display: flex;
            justify-content: center;
            margin-bottom: 2rem;
        }

        .voice-button {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 1rem;
            padding: 2rem 3rem;
            background: linear-gradient(135deg, var(--sage-green) 0%, var(--accent-green) 100%);
            color: var(--primary-white);
            border: var(--border-width) solid var(--primary-black);
            box-shadow: var(--shadow-offset) var(--shadow-offset) 0 var(--primary-black);
            cursor: pointer;
            transition: var(--transition);
            font-family: inherit;
            font-size: 1rem;
            font-weight: 600;
        }

        .voice-button:hover {
            transform: translate(2px, 2px);
            box-shadow: 2px 2px 0 var(--primary-black);
        }

        .voice-button:active {
            transform: translate(var(--shadow-offset), var(--shadow-offset));
            box-shadow: none;
        }

        .voice-button.active {
            background: linear-gradient(135deg, #27ae60 0%, #229954 100%);
            animation: pulse-button 1.5s infinite;
        }

        @keyframes pulse-button {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.05); }
        }

        .voice-button:disabled {
            background: #cccccc;
            cursor: not-allowed;
            opacity: 0.6;
        }

        .mic-icon {
            width: 48px;
            height: 48px;
            stroke-width: 2.5;
        }

        .button-text {
            font-size: 1rem;
            font-weight: 600;
        }

        .transcript-container {
            border: var(--border-width) solid var(--primary-black);
            padding: 1.5rem;
            background: var(--primary-white);
        }

        .transcript-container h3 {
            font-size: 1.25rem;
            margin-bottom: 1rem;
            font-weight: 600;
        }

        .transcript {
            max-height: 300px;
            overflow-y: auto;
            padding: 1rem;
            background: #fafafa;
            border: 2px solid #e0e0e0;
            border-radius: 4px;
        }

        .transcript-empty {
            color: #999;
            font-style: italic;
            text-align: center;
        }

        .transcript-message {
            margin-bottom: 1rem;
            padding: 0.75rem;
            border-left: 3px solid var(--sage-green);
            background: var(--primary-white);
        }

        .transcript-message.user {
            border-left-color: var(--sage-green);
        }

        .transcript-message.agent {
            border-left-color: #3498db;
        }

        .transcript-message .speaker {
            font-weight: 600;
            font-size: 0.85rem;
            margin-bottom: 0.25rem;
            color: #666;
        }

        .transcript-message .message-text {
            font-size: 0.95rem;
            line-height: 1.5;
        }

        footer {
            text-align: center;
            padding-top: 1.5rem;
            border-top: var(--border-width) solid var(--primary-black);
            color: #666;
            font-size: 0.85rem;
        }

        /* Responsive Design */
        @media (max-width: 640px) {
            .container {
                padding: 1.5rem;
            }

            h1 {
                font-size: 2rem;
            }

            .voice-button {
                padding: 1.5rem 2rem;
            }

            .mic-icon {
                width: 40px;
                height: 40px;
            }

            .transcript {
                max-height: 200px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>4-help</h1>
            <p class="subtitle">Voice Assistant</p>
        </header>

        <main>
            <div class="voice-interface">
                <div class="status-indicator" id="statusIndicator">
                    <div class="status-dot"></div>
                    <span class="status-text" id="statusText">Ready to start</span>
                </div>

                <div class="voice-control">
                    <button id="voiceButton" class="voice-button" aria-label="Start conversation">
                        <svg class="mic-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"></path>
                            <path d="M19 10v2a7 7 0 0 1-14 0v-2"></path>
                            <line x1="12" y1="19" x2="12" y2="23"></line>
                            <line x1="8" y1="23" x2="16" y2="23"></line>
                        </svg>
                        <span class="button-text" id="buttonText">Start Conversation</span>
                    </button>
                </div>

                <div class="transcript-container" id="transcriptContainer">
                    <h3>Conversation</h3>
                    <div class="transcript" id="transcript">
                        <p class="transcript-empty">Your conversation will appear here...</p>
                    </div>
                </div>
            </div>
        </main>

        <footer>
            <p>Powered by ElevenLabs Conversational AI</p>
        </footer>
    </div>

    <script>
        /**
         * 4-help App - ElevenLabs Voice Agent Integration
         * Voice conversation interface using ElevenLabs Conversational AI
         */

        class VoiceAssistant {
            constructor() {
                this.isConnected = false;
                this.isRecording = false;
                this.websocket = null;
                this.audioContext = null;
                this.mediaStream = null;
                // Agent ID embedded directly
                this.agentId = 'agent_2701kh4p4ehpe03a94h8pmhbxxa6';

                this.initializeElements();
                this.attachEventListeners();
                this.updateStatus('ready', 'Ready to start');
            }

            initializeElements() {
                this.voiceButton = document.getElementById('voiceButton');
                this.buttonText = document.getElementById('buttonText');
                this.statusIndicator = document.getElementById('statusIndicator');
                this.statusText = document.getElementById('statusText');
                this.transcript = document.getElementById('transcript');
            }

            attachEventListeners() {
                this.voiceButton.addEventListener('click', () => this.toggleConversation());
            }

            async toggleConversation() {
                if (this.isConnected) {
                    this.stopConversation();
                } else {
                    await this.startConversation();
                }
            }

            async startConversation() {
                try {
                    this.updateStatus('connecting', 'Connecting...');
                    this.voiceButton.disabled = true;

                    // Request microphone access
                    this.mediaStream = await navigator.mediaDevices.getUserMedia({
                        audio: {
                            echoCancellation: true,
                            noiseSuppression: true,
                            autoGainControl: true
                        }
                    });

                    // Initialize audio context
                    this.audioContext = new (window.AudioContext || window.webkitAudioContext)({
                        sampleRate: 16000
                    });

                    // Connect to ElevenLabs Conversational AI
                    await this.connectToElevenLabs();

                    this.isConnected = true;
                    this.isRecording = true;
                    this.updateStatus('active', 'Listening...');
                    this.voiceButton.classList.add('active');
                    this.buttonText.textContent = 'Stop Conversation';
                    this.voiceButton.disabled = false;

                    this.addTranscriptMessage('system', 'Conversation started');
                } catch (error) {
                    console.error('Error starting conversation:', error);
                    this.updateStatus('error', 'Error: ' + error.message);
                    this.voiceButton.disabled = false;

                    if (error.name === 'NotAllowedError') {
                        alert('Microphone access is required. Please allow microphone permissions and try again.');
                    } else {
                        alert('Failed to start conversation: ' + error.message);
                    }
                }
            }

            async connectToElevenLabs() {
                return new Promise((resolve, reject) => {
                    // ElevenLabs Conversational AI WebSocket endpoint
                    const wsUrl = `wss://api.elevenlabs.io/v1/convai/conversation?agent_id=${this.agentId}`;

                    this.websocket = new WebSocket(wsUrl);

                    this.websocket.onopen = () => {
                        console.log('Connected to ElevenLabs');
                        this.startAudioStreaming();
                        resolve();
                    };

                    this.websocket.onmessage = (event) => {
                        this.handleWebSocketMessage(event);
                    };

                    this.websocket.onerror = (error) => {
                        console.error('WebSocket error:', error);
                        reject(new Error('Failed to connect to ElevenLabs. Check your connection.'));
                    };

                    this.websocket.onclose = () => {
                        console.log('Disconnected from ElevenLabs');
                        if (this.isConnected) {
                            this.stopConversation();
                        }
                    };
                });
            }

            startAudioStreaming() {
                if (!this.mediaStream || !this.audioContext) return;

                const source = this.audioContext.createMediaStreamSource(this.mediaStream);
                const processor = this.audioContext.createScriptProcessor(4096, 1, 1);

                source.connect(processor);
                processor.connect(this.audioContext.destination);

                processor.onaudioprocess = (e) => {
                    if (!this.isRecording || !this.websocket || this.websocket.readyState !== WebSocket.OPEN) {
                        return;
                    }

                    // Get audio data and convert to appropriate format
                    const audioData = e.inputBuffer.getChannelData(0);
                    const int16Data = this.floatTo16BitPCM(audioData);

                    // Send audio data to ElevenLabs
                    this.websocket.send(int16Data);
                };

                this.audioProcessor = processor;
            }

            floatTo16BitPCM(float32Array) {
                const int16Array = new Int16Array(float32Array.length);
                for (let i = 0; i < float32Array.length; i++) {
                    const s = Math.max(-1, Math.min(1, float32Array[i]));
                    int16Array[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                }
                return int16Array.buffer;
            }

            handleWebSocketMessage(event) {
                try {
                    // Handle different message types from ElevenLabs
                    if (event.data instanceof Blob) {
                        // Audio response from agent
                        this.playAudioResponse(event.data);
                    } else {
                        // Text/JSON response
                        const data = JSON.parse(event.data);

                        if (data.type === 'transcript') {
                            if (data.role === 'user') {
                                this.addTranscriptMessage('user', data.text);
                            } else if (data.role === 'agent') {
                                this.addTranscriptMessage('agent', data.text);
                            }
                        }

                        if (data.type === 'interruption') {
                            console.log('Agent interrupted');
                        }
                    }
                } catch (error) {
                    console.error('Error handling message:', error);
                }
            }

            async playAudioResponse(audioBlob) {
                try {
                    const arrayBuffer = await audioBlob.arrayBuffer();
                    const audioBuffer = await this.audioContext.decodeAudioData(arrayBuffer);

                    const source = this.audioContext.createBufferSource();
                    source.buffer = audioBuffer;
                    source.connect(this.audioContext.destination);
                    source.start(0);

                    this.updateStatus('active', 'Agent speaking...');

                    source.onended = () => {
                        if (this.isConnected) {
                            this.updateStatus('active', 'Listening...');
                        }
                    };
                } catch (error) {
                    console.error('Error playing audio:', error);
                }
            }

            stopConversation() {
                this.isConnected = false;
                this.isRecording = false;

                // Close WebSocket
                if (this.websocket) {
                    this.websocket.close();
                    this.websocket = null;
                }

                // Stop audio processor
                if (this.audioProcessor) {
                    this.audioProcessor.disconnect();
                    this.audioProcessor = null;
                }

                // Stop media stream
                if (this.mediaStream) {
                    this.mediaStream.getTracks().forEach(track => track.stop());
                    this.mediaStream = null;
                }

                // Close audio context
                if (this.audioContext) {
                    this.audioContext.close();
                    this.audioContext = null;
                }

                this.updateStatus('ready', 'Ready to start');
                this.voiceButton.classList.remove('active');
                this.buttonText.textContent = 'Start Conversation';
                this.voiceButton.disabled = false;

                this.addTranscriptMessage('system', 'Conversation ended');
            }

            updateStatus(state, text) {
                this.statusIndicator.className = `status-indicator ${state}`;
                this.statusText.textContent = text;
            }

            addTranscriptMessage(speaker, text) {
                // Remove empty message if present
                const emptyMessage = this.transcript.querySelector('.transcript-empty');
                if (emptyMessage) {
                    emptyMessage.remove();
                }

                const messageDiv = document.createElement('div');
                messageDiv.className = `transcript-message ${speaker}`;

                const speakerLabel = document.createElement('div');
                speakerLabel.className = 'speaker';
                speakerLabel.textContent = speaker === 'user' ? 'You' :
                                           speaker === 'agent' ? 'Assistant' :
                                           'System';

                const messageText = document.createElement('div');
                messageText.className = 'message-text';
                messageText.textContent = text;

                messageDiv.appendChild(speakerLabel);
                messageDiv.appendChild(messageText);
                this.transcript.appendChild(messageDiv);

                // Auto-scroll to bottom
                this.transcript.scrollTop = this.transcript.scrollHeight;
            }
        }

        // Initialize the app when DOM is ready
        document.addEventListener('DOMContentLoaded', () => {
            // Check for HTTPS (required for microphone access)
            if (location.protocol !== 'https:' && location.hostname !== 'localhost' && location.hostname !== '127.0.0.1') {
                alert('This app requires HTTPS to access the microphone. Please use HTTPS or run on localhost.');
            }

            // Initialize voice assistant
            window.voiceAssistant = new VoiceAssistant();
        });
    </script>
</body>
</html>
